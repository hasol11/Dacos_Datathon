{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasol11/Dacos_Datathon/blob/main/%EC%A0%9C2%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%86%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgxQhFR6GH8V"
      },
      "source": [
        "1. 구글 드라이브 불러오기 및 모듈 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J09yQeJdYqtO",
        "outputId": "4c17454a-a0c6-4ae0-f9c3-698967dc69fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T3lswPVY_19",
        "outputId": "e5520179-ece4-496b-f443-2dca3e232450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ijson\n",
            "  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/114.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ijson\n",
            "Successfully installed ijson-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ijson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpYHpNslZPC2",
        "outputId": "25811d96-8923-4e33-a55f-23f13395b3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예상 행(row) 개수: 4639821\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import ijson\n",
        "import pandas as pd\n",
        "\n",
        "# Zip 파일 경로\n",
        "zip_file_path = '/content/drive/MyDrive/Colab Notebooks/숙명여대/20230101.zip'\n",
        "\n",
        "# Zip 파일 열기\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
        "    # JSON 파일 추출\n",
        "    json_file_name = z.namelist()[0]\n",
        "    with z.open(json_file_name) as file:\n",
        "        row_count = 0\n",
        "        max_columns = 0\n",
        "\n",
        "        # 데이터 샘플링\n",
        "        objects = ijson.items(file, 'item')\n",
        "        for obj in objects:\n",
        "            row_count += 1\n",
        "\n",
        "\n",
        "        print(f\"예상 행(row) 개수: {row_count}\")\n",
        "\n",
        "        # 전체 데이터를 읽기 위해 파일 포인터를 다시 시작점으로 이동\n",
        "        file.seek(0)\n",
        "\n",
        "        # # 데이터프레임 생성\n",
        "        # data = []\n",
        "        # objects = ijson.items(file, 'item')\n",
        "        # for obj in objects:\n",
        "        #     data.append(obj)\n",
        "        # df = pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb988WIhGcqR"
      },
      "source": [
        "2. json.zip 파일 압축 풀기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVK6_8EZcJbT"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_file = zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/숙명여대/20230101.zip')\n",
        "zip_file.extractall('/content/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp_PyLx7iG2V",
        "outputId": "51fd586b-09ce-4e3b-f2c7-6bdc5daab9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     yyyymmdd                              ouid  gender  age_group  age  \\\n",
            "0  2023-01-01  555C4079F359F10B49F4A70915651130       1          3   31   \n",
            "1  2023-01-01  5516CEC80BDB611DA8BA1B186CAE3174       2          4   47   \n",
            "2  2023-01-01  692CCFB70187ACFEB8E8197DA8FD7A33       2          4   40   \n",
            "3  2023-01-01  B62E59C0F134B4DEE2F3D0A15D0494C6       2          4   40   \n",
            "4  2023-01-01  5A2776C119C6AF707C869DC477807929       1          5   55   \n",
            "\n",
            "   job_type city   gu            user_time  duration             domain  \\\n",
            "0         3            2023-01-01 16:19:56        17  m.brand.naver.com   \n",
            "1         1   서울  은평구  2023-01-01 10:31:34       838   m.cafe.naver.com   \n",
            "2         1   전남  목포시  2023-01-01 12:06:30       102   n.news.naver.com   \n",
            "3         4   경기  시흥시  2023-01-01 13:12:23        16   n.news.naver.com   \n",
            "4         1   서울  종로구  2023-01-01 14:51:07         9   n.news.naver.com   \n",
            "\n",
            "  platform_name                              crawled_title  \\\n",
            "0       android                                     코카콜라음료   \n",
            "1       android                                     네이버 카페   \n",
            "2       android  ‘삭발’ 이승기 “물러설 수 없다” 호소에…문체부, 불공정 관행 뜯어고친다   \n",
            "3       android  ‘삭발’ 이승기 “물러설 수 없다” 호소에…문체부, 불공정 관행 뜯어고친다   \n",
            "4       android  ‘삭발’ 이승기 “물러설 수 없다” 호소에…문체부, 불공정 관행 뜯어고친다   \n",
            "\n",
            "                                                 url media_name media_section  \\\n",
            "0  https://m.brand.naver.com/cocacola/sidemenu?pr...                            \n",
            "1  https://m.cafe.naver.com/ca-fe/web/cafes/21820...                            \n",
            "2  https://n.news.naver.com/article/016/000208520...      헤럴드경제            생활   \n",
            "3  https://n.news.naver.com/article/016/000208520...      헤럴드경제            생활   \n",
            "4  https://n.news.naver.com/article/016/000208520...      헤럴드경제            생활   \n",
            "\n",
            "  search_keyword  \n",
            "0                 \n",
            "1                 \n",
            "2                 \n",
            "3                 \n",
            "4                 \n"
          ]
        }
      ],
      "source": [
        "import ijson\n",
        "import pandas as pd\n",
        "\n",
        "# JSON 파일 경로\n",
        "file_path = '/content/20230101.json'\n",
        "\n",
        "# 상위 항목 수\n",
        "n = 5\n",
        "\n",
        "# 데이터 스트리밍\n",
        "with open(file_path, 'r') as file:\n",
        "    objects = ijson.items(file, 'item')  # 'item'은 JSON의 루트 키에 따라 조정\n",
        "    head_data = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        if i >= n:\n",
        "            break\n",
        "        head_data.append(obj)\n",
        "\n",
        "# DataFrame으로 변환\n",
        "df = pd.DataFrame(head_data)\n",
        "\n",
        "# DataFrame 출력\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wuEven2xmPtz"
      },
      "outputs": [],
      "source": [
        "#전체 데이터 압축 풀어 파일로 만들기\n",
        "import zipfile\n",
        "zip_file=zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/숙명여대/20230201.zip')\n",
        "zip_file.extractall('/content')\n",
        "\n",
        "zip_file=zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/숙명여대/20230301.zip')\n",
        "zip_file.extractall('/content')\n",
        "\n",
        "zip_file=zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/숙명여대/20230401.zip')\n",
        "zip_file.extractall('/content')\n",
        "\n",
        "zip_file=zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/숙명여대/20230501.zip')\n",
        "zip_file.extractall('/content')\n",
        "\n",
        "zip_file=zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/숙명여대/20231201.zip')\n",
        "zip_file.extractall('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezw1TMXeGkMh"
      },
      "source": [
        "3. 필요없는 칼럼 삭제하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zw7r0XfKo2Zx",
        "outputId": "090bd860-49bc-4981-c878-3a7adf12d247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/processed_20230101.json\n"
          ]
        }
      ],
      "source": [
        "import ijson\n",
        "import json\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/20230101.json'\n",
        "output_file_path = '/content/processed_20230101.json'\n",
        "\n",
        "# 제거할 키 목록\n",
        "keys_to_remove = ['ouid', 'age', 'gu', 'url', 'user_time', 'domain', 'media_name', 'media_section', 'search_keyword']\n",
        "\n",
        "\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    output_file.write('[')\n",
        "\n",
        "    # JSON 파일을 스트리밍 방식으로 처리\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        parser = ijson.items(input_file, 'item')  # JSON에서 각 항목을 스트리밍\n",
        "\n",
        "        first = True\n",
        "        for item in parser:\n",
        "            # 불필요한 키 제거\n",
        "            for key in keys_to_remove:\n",
        "                item.pop(key, None)\n",
        "\n",
        "            # JSON 파일에 항목 쓰기\n",
        "            if not first:\n",
        "                output_file.write(',')\n",
        "            output_file.write(json.dumps(item, indent=4))\n",
        "            first = False\n",
        "\n",
        "    output_file.write(']')  # JSON 배열의 끝\n",
        "\n",
        "print(f'{output_file_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BLo3KFMC8KQB",
        "outputId": "754d2c6c-ea99-4099-ee05-1510701d2a3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/processed_20230201.json\n"
          ]
        }
      ],
      "source": [
        "import ijson\n",
        "import json\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/20230201.json'\n",
        "output_file_path = '/content/processed_20230201.json'\n",
        "\n",
        "# 제거할 키 목록\n",
        "keys_to_remove = ['ouid', 'age', 'gu', 'url', 'user_time', 'domain', 'media_name', 'media_section', 'search_keyword']\n",
        "\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    output_file.write('[')\n",
        "\n",
        "    # JSON 파일을 스트리밍 방식으로 처리\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        parser = ijson.items(input_file, 'item')  # JSON에서 각 항목을 스트리밍\n",
        "\n",
        "        first = True\n",
        "        for item in parser:\n",
        "            # 불필요한 키 제거\n",
        "            for key in keys_to_remove:\n",
        "                item.pop(key, None)\n",
        "\n",
        "            # JSON 파일에 항목 쓰기\n",
        "            if not first:\n",
        "                output_file.write(',')\n",
        "            output_file.write(json.dumps(item, indent=4))\n",
        "            first = False\n",
        "\n",
        "    output_file.write(']')  # JSON 배열의 끝\n",
        "\n",
        "print(f'{output_file_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x5CdsA9N9Fd-",
        "outputId": "8f07fcc3-ecd3-49f7-b62d-c86cc9c64cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/processed_20230301.json\n"
          ]
        }
      ],
      "source": [
        "import ijson\n",
        "import json\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/20230301.json'\n",
        "output_file_path = '/content/processed_20230301.json'\n",
        "\n",
        "# 제거할 키 목록\n",
        "keys_to_remove = ['ouid', 'age', 'gu', 'url', 'user_time', 'domain', 'media_name', 'media_section', 'search_keyword']\n",
        "\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    output_file.write('[')  # JSON 배열의 시작\n",
        "\n",
        "    # JSON 파일을 스트리밍 방식으로 처리\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        parser = ijson.items(input_file, 'item')  # JSON에서 각 항목을 스트리밍\n",
        "\n",
        "        first = True\n",
        "        for item in parser:\n",
        "            # 불필요한 키 제거\n",
        "            for key in keys_to_remove:\n",
        "                item.pop(key, None)\n",
        "\n",
        "            # JSON 파일에 항목 쓰기\n",
        "            if not first:\n",
        "                output_file.write(',')\n",
        "            output_file.write(json.dumps(item, indent=4))\n",
        "            first = False\n",
        "\n",
        "    output_file.write(']')  # JSON 배열의 끝\n",
        "\n",
        "print(f'{output_file_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UcDfqtvn-Q5b",
        "outputId": "8c16d760-ffb5-4a22-c09d-7f5f9c7b4c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/processed_20230401.json\n"
          ]
        }
      ],
      "source": [
        "import ijson\n",
        "import json\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/20230401.json'\n",
        "output_file_path = '/content/processed_20230401.json'\n",
        "\n",
        "# 제거할 키 목록\n",
        "keys_to_remove = ['ouid', 'age', 'gu', 'url', 'user_time', 'domain', 'media_name', 'media_section', 'search_keyword']\n",
        "\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    output_file.write('[')  # JSON 배열의 시작\n",
        "\n",
        "    # JSON 파일을 스트리밍 방식으로 처리\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        parser = ijson.items(input_file, 'item')  # JSON에서 각 항목을 스트리밍\n",
        "\n",
        "        first = True\n",
        "        for item in parser:\n",
        "            # 불필요한 키 제거\n",
        "            for key in keys_to_remove:\n",
        "                item.pop(key, None)\n",
        "\n",
        "            # JSON 파일에 항목 쓰기\n",
        "            if not first:\n",
        "                output_file.write(',')\n",
        "            output_file.write(json.dumps(item, indent=4))\n",
        "            first = False\n",
        "\n",
        "    output_file.write(']')  # JSON 배열의 끝\n",
        "\n",
        "print(f'{output_file_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jv0gVS33BMa7",
        "outputId": "17ec549e-7e28-4e8a-e536-17930b313620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/processed_20230501.json\n"
          ]
        }
      ],
      "source": [
        "import ijson\n",
        "import json\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/20230501.json'\n",
        "output_file_path = '/content/processed_20230501.json'\n",
        "\n",
        "# 제거할 키 목록\n",
        "keys_to_remove = ['ouid', 'age', 'gu', 'url', 'user_time', 'domain', 'media_name', 'media_section', 'search_keyword']\n",
        "\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    output_file.write('[')  # JSON 배열의 시작\n",
        "\n",
        "    # JSON 파일을 스트리밍 방식으로 처리\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        parser = ijson.items(input_file, 'item')  # JSON에서 각 항목을 스트리밍\n",
        "\n",
        "        first = True\n",
        "        for item in parser:\n",
        "            # 불필요한 키 제거\n",
        "            for key in keys_to_remove:\n",
        "                item.pop(key, None)\n",
        "\n",
        "            # JSON 파일에 항목 쓰기\n",
        "            if not first:\n",
        "                output_file.write(',')\n",
        "            output_file.write(json.dumps(item, indent=4))\n",
        "            first = False\n",
        "\n",
        "    output_file.write(']')  # JSON 배열의 끝\n",
        "\n",
        "print(f'{output_file_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3Vd5N8hCPrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb69dcd-f077-4101-8c00-35b5eeda72e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/processed_20231201.json\n"
          ]
        }
      ],
      "source": [
        "import ijson\n",
        "import json\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/20231201.json'\n",
        "output_file_path = '/content/processed_20231201.json'\n",
        "\n",
        "# 제거할 키 목록\n",
        "keys_to_remove = ['ouid', 'age', 'gu', 'url', 'user_time', 'domain', 'media_name', 'media_section', 'search_keyword']\n",
        "\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    output_file.write('[')  # JSON 배열의 시작\n",
        "\n",
        "    # JSON 파일을 스트리밍 방식으로 처리\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        parser = ijson.items(input_file, 'item')  # JSON에서 각 항목을 스트리밍\n",
        "\n",
        "        first = True\n",
        "        for item in parser:\n",
        "            # 불필요한 키 제거\n",
        "            for key in keys_to_remove:\n",
        "                item.pop(key, None)\n",
        "\n",
        "            # JSON 파일에 항목 쓰기\n",
        "            if not first:\n",
        "                output_file.write(',')\n",
        "            output_file.write(json.dumps(item, indent=4))\n",
        "            first = False\n",
        "\n",
        "    output_file.write(']')  # JSON 배열의 끝\n",
        "\n",
        "print(f'{output_file_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwIjea9QG1nR"
      },
      "source": [
        "4. json 파일 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPUuG7n86cFS"
      },
      "outputs": [],
      "source": [
        "import ijson\n",
        "import pandas as pd\n",
        "\n",
        "# 전처리된 JSON 파일 경로\n",
        "file_path = '/content/processed_20230101.json'\n",
        "\n",
        "# 상위 항목 수\n",
        "n = 5\n",
        "\n",
        "# 데이터 스트리밍\n",
        "with open(file_path, 'r') as file:\n",
        "    objects = ijson.items(file, 'item')  # 'item'은 JSON의 루트 키에 따라 조정\n",
        "    head_data = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        if i >= n:\n",
        "            break\n",
        "        head_data.append(obj)\n",
        "\n",
        "# DataFrame으로 변환\n",
        "df = pd.DataFrame([head_data])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO5g7NQJ5TXG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "fad57a39-e43b-4519-8868-3d7d58c5c7da"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['yyyymmdd', 'gender', 'age_group', 'job_type', 'city', 'duration',\\n       'platform_name', 'crawled_title'],\\n      dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f15184c972c6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print([df.head(30)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m'yyyymmdd'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'gender'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'age_group'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'job_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'city'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'duration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'platform_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'crawled_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6113\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6117\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6175\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6176\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6178\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['yyyymmdd', 'gender', 'age_group', 'job_type', 'city', 'duration',\\n       'platform_name', 'crawled_title'],\\n      dtype='object')] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "#print([df.head(30)])\n",
        "df[[ 'yyyymmdd',  'gender', 'age_group', 'job_type', 'city', 'duration', 'platform_name', 'crawled_title']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehJXtm2iG98h"
      },
      "source": [
        "5. 결측치 제거, 나이 구간 설정 및 샘플링 진행후 csv 파일 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBx4HZHruRSL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ijson\n",
        "import os\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/processed_20230101.json'\n",
        "output_csv_file = '/content/final_20230101.csv'\n",
        "\n",
        "# YB와 OB 그룹의 나이 구간 설정\n",
        "yb_group_range = range(0, 4)\n",
        "ob_group_range = range(4, 10)\n",
        "\n",
        "# 샘플 크기 설정\n",
        "total_sample_size = 40000\n",
        "yb_ratio = 0.5\n",
        "ob_ratio = 1 - yb_ratio\n",
        "\n",
        "yb_sample_size = int(total_sample_size * yb_ratio)\n",
        "ob_sample_size = total_sample_size - yb_sample_size\n",
        "\n",
        "# 샘플링을 추적하기 위한 변수\n",
        "yb_current_sampled = 0\n",
        "ob_current_sampled = 0\n",
        "\n",
        "# 한 번에 처리할 청크 크기 (10만 개씩)\n",
        "chunk_size = 100000\n",
        "\n",
        "\n",
        "# JSON 파일을 청크로 나눠서 스트리밍 방식으로 처리\n",
        "with open(input_file_path, 'r') as file:\n",
        "    objects = ijson.items(file, 'item')\n",
        "\n",
        "    chunk = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        chunk.append(obj)\n",
        "\n",
        "        # 청크 크기에 도달할 때마다 처리\n",
        "        if (i + 1) % chunk_size == 0:\n",
        "\n",
        "            # 청크를 DataFrame으로 변환\n",
        "            df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "            # 결측치 제거\n",
        "            df_chunk = df_chunk.dropna()\n",
        "\n",
        "            # 필요 없는 컬럼 제거\n",
        "            df_chunk = df_chunk.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "            # YB 그룹과 OB 그룹으로 나누기\n",
        "            yb_group = df_chunk[df_chunk['age_group'].isin(yb_group_range)]\n",
        "            ob_group = df_chunk[df_chunk['age_group'].isin(ob_group_range)]\n",
        "\n",
        "            # YB 그룹 샘플링\n",
        "            if yb_current_sampled < yb_sample_size:\n",
        "                yb_sample_chunk_size = min(yb_sample_size - yb_current_sampled, len(yb_group))\n",
        "                yb_sample_chunk = yb_group.sample(n=yb_sample_chunk_size, random_state=42)\n",
        "                yb_current_sampled += yb_sample_chunk_size\n",
        "            else:\n",
        "                yb_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # OB 그룹 샘플링\n",
        "            if ob_current_sampled < ob_sample_size:\n",
        "                ob_sample_chunk_size = min(ob_sample_size - ob_current_sampled, len(ob_group))\n",
        "                ob_sample_chunk = ob_group.sample(n=ob_sample_chunk_size, random_state=42)\n",
        "                ob_current_sampled += ob_sample_chunk_size\n",
        "            else:\n",
        "                ob_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # YB와 OB 샘플을 합치기\n",
        "            combined_chunk = pd.concat([yb_sample_chunk, ob_sample_chunk])\n",
        "\n",
        "            # CSV 파일로 저장\n",
        "            combined_chunk.to_csv(output_csv_file, mode='a', header=not os.path.exists(output_csv_file), index=False)\n",
        "\n",
        "            # 청크 비우기\n",
        "            chunk = []\n",
        "\n",
        "            # 샘플이 모두 완료되면 중단\n",
        "            if yb_current_sampled >= yb_sample_size and ob_current_sampled >= ob_sample_size:\n",
        "                break\n",
        "\n",
        "    # 마지막 남은 청크 처리\n",
        "    if chunk:\n",
        "        df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "        # 결측치 제거\n",
        "        df_chunk = df_chunk.dropna()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fhtB2gc8mg-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ijson\n",
        "import os\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/processed_20230201.json'\n",
        "output_csv_file = '/content/final_20230201.csv'\n",
        "\n",
        "# YB와 OB 그룹의 나이 구간 설정\n",
        "yb_group_range = range(0, 4)\n",
        "ob_group_range = range(4, 10)\n",
        "\n",
        "# 샘플 크기 설정\n",
        "total_sample_size = 40000\n",
        "yb_ratio = 0.5\n",
        "ob_ratio = 1 - yb_ratio\n",
        "\n",
        "yb_sample_size = int(total_sample_size * yb_ratio)\n",
        "ob_sample_size = total_sample_size - yb_sample_size\n",
        "\n",
        "# 샘플링을 추적하기 위한 변수\n",
        "yb_current_sampled = 0\n",
        "ob_current_sampled = 0\n",
        "\n",
        "# 한 번에 처리할 청크 크기 (10만 개씩)\n",
        "chunk_size = 100000\n",
        "\n",
        "\n",
        "# JSON 파일을 청크로 나눠서 스트리밍 방식으로 처리\n",
        "with open(input_file_path, 'r') as file:\n",
        "    objects = ijson.items(file, 'item')\n",
        "\n",
        "    chunk = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        chunk.append(obj)\n",
        "\n",
        "        # 청크 크기에 도달할 때마다 처리\n",
        "        if (i + 1) % chunk_size == 0:\n",
        "\n",
        "            # 청크를 DataFrame으로 변환\n",
        "            df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "            # 결측치 제거\n",
        "            df_chunk = df_chunk.dropna()\n",
        "\n",
        "            # 필요 없는 컬럼 제거\n",
        "            df_chunk = df_chunk.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "            # YB 그룹과 OB 그룹으로 나누기\n",
        "            yb_group = df_chunk[df_chunk['age_group'].isin(yb_group_range)]\n",
        "            ob_group = df_chunk[df_chunk['age_group'].isin(ob_group_range)]\n",
        "\n",
        "            # YB 그룹 샘플링\n",
        "            if yb_current_sampled < yb_sample_size:\n",
        "                yb_sample_chunk_size = min(yb_sample_size - yb_current_sampled, len(yb_group))\n",
        "                yb_sample_chunk = yb_group.sample(n=yb_sample_chunk_size, random_state=42)\n",
        "                yb_current_sampled += yb_sample_chunk_size\n",
        "            else:\n",
        "                yb_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # OB 그룹 샘플링\n",
        "            if ob_current_sampled < ob_sample_size:\n",
        "                ob_sample_chunk_size = min(ob_sample_size - ob_current_sampled, len(ob_group))\n",
        "                ob_sample_chunk = ob_group.sample(n=ob_sample_chunk_size, random_state=42)\n",
        "                ob_current_sampled += ob_sample_chunk_size\n",
        "            else:\n",
        "                ob_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # YB와 OB 샘플을 합치기\n",
        "            combined_chunk = pd.concat([yb_sample_chunk, ob_sample_chunk])\n",
        "\n",
        "            # CSV 파일로 저장\n",
        "            combined_chunk.to_csv(output_csv_file, mode='a', header=not os.path.exists(output_csv_file), index=False)\n",
        "\n",
        "            # 청크 비우기\n",
        "            chunk = []\n",
        "\n",
        "            # 샘플이 모두 완료되면 중단\n",
        "            if yb_current_sampled >= yb_sample_size and ob_current_sampled >= ob_sample_size:\n",
        "                break\n",
        "\n",
        "    # 마지막 남은 청크 처리\n",
        "    if chunk:\n",
        "        df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "        # 결측치 제거\n",
        "        df_chunk = df_chunk.dropna()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbYTE-_88rNQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ijson\n",
        "import os\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/processed_20230301.json'\n",
        "output_csv_file = '/content/final_20230301.csv'\n",
        "\n",
        "# YB와 OB 그룹의 나이 구간 설정\n",
        "yb_group_range = range(0, 4)\n",
        "ob_group_range = range(4, 10)\n",
        "\n",
        "# 샘플 크기 설정\n",
        "total_sample_size = 40000\n",
        "yb_ratio = 0.5\n",
        "ob_ratio = 1 - yb_ratio\n",
        "\n",
        "yb_sample_size = int(total_sample_size * yb_ratio)\n",
        "ob_sample_size = total_sample_size - yb_sample_size\n",
        "\n",
        "# 샘플링을 추적하기 위한 변수\n",
        "yb_current_sampled = 0\n",
        "ob_current_sampled = 0\n",
        "\n",
        "# 한 번에 처리할 청크 크기 (10만 개씩)\n",
        "chunk_size = 100000\n",
        "\n",
        "\n",
        "# JSON 파일을 청크로 나눠서 스트리밍 방식으로 처리\n",
        "with open(input_file_path, 'r') as file:\n",
        "    objects = ijson.items(file, 'item')\n",
        "\n",
        "    chunk = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        chunk.append(obj)\n",
        "\n",
        "        # 청크 크기에 도달할 때마다 처리\n",
        "        if (i + 1) % chunk_size == 0:\n",
        "\n",
        "            # 청크를 DataFrame으로 변환\n",
        "            df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "            # 결측치 제거\n",
        "            df_chunk = df_chunk.dropna()\n",
        "\n",
        "            # 필요 없는 컬럼 제거\n",
        "            df_chunk = df_chunk.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "            # YB 그룹과 OB 그룹으로 나누기\n",
        "            yb_group = df_chunk[df_chunk['age_group'].isin(yb_group_range)]\n",
        "            ob_group = df_chunk[df_chunk['age_group'].isin(ob_group_range)]\n",
        "\n",
        "            # YB 그룹 샘플링\n",
        "            if yb_current_sampled < yb_sample_size:\n",
        "                yb_sample_chunk_size = min(yb_sample_size - yb_current_sampled, len(yb_group))\n",
        "                yb_sample_chunk = yb_group.sample(n=yb_sample_chunk_size, random_state=42)\n",
        "                yb_current_sampled += yb_sample_chunk_size\n",
        "            else:\n",
        "                yb_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # OB 그룹 샘플링\n",
        "            if ob_current_sampled < ob_sample_size:\n",
        "                ob_sample_chunk_size = min(ob_sample_size - ob_current_sampled, len(ob_group))\n",
        "                ob_sample_chunk = ob_group.sample(n=ob_sample_chunk_size, random_state=42)\n",
        "                ob_current_sampled += ob_sample_chunk_size\n",
        "            else:\n",
        "                ob_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # YB와 OB 샘플을 합치기\n",
        "            combined_chunk = pd.concat([yb_sample_chunk, ob_sample_chunk])\n",
        "\n",
        "            # CSV 파일로 저장\n",
        "            combined_chunk.to_csv(output_csv_file, mode='a', header=not os.path.exists(output_csv_file), index=False)\n",
        "\n",
        "            # 청크 비우기\n",
        "            chunk = []\n",
        "\n",
        "            # 샘플이 모두 완료되면 중단\n",
        "            if yb_current_sampled >= yb_sample_size and ob_current_sampled >= ob_sample_size:\n",
        "                break\n",
        "\n",
        "    # 마지막 남은 청크 처리\n",
        "    if chunk:\n",
        "        df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "        # 결측치 제거\n",
        "        df_chunk = df_chunk.dropna()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS3d8Tyk84d-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ijson\n",
        "import os\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/processed_20230401.json'\n",
        "output_csv_file = '/content/final_20230401.csv'\n",
        "\n",
        "# YB와 OB 그룹의 나이 구간 설정\n",
        "yb_group_range = range(0, 4)\n",
        "ob_group_range = range(4, 10)\n",
        "\n",
        "# 샘플 크기 설정\n",
        "total_sample_size = 40000\n",
        "yb_ratio = 0.5\n",
        "ob_ratio = 1 - yb_ratio\n",
        "\n",
        "yb_sample_size = int(total_sample_size * yb_ratio)\n",
        "ob_sample_size = total_sample_size - yb_sample_size\n",
        "\n",
        "# 샘플링을 추적하기 위한 변수\n",
        "yb_current_sampled = 0\n",
        "ob_current_sampled = 0\n",
        "\n",
        "# 한 번에 처리할 청크 크기 (10만 개씩)\n",
        "chunk_size = 100000\n",
        "\n",
        "\n",
        "# JSON 파일을 청크로 나눠서 스트리밍 방식으로 처리\n",
        "with open(input_file_path, 'r') as file:\n",
        "    objects = ijson.items(file, 'item')\n",
        "\n",
        "    chunk = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        chunk.append(obj)\n",
        "\n",
        "        # 청크 크기에 도달할 때마다 처리\n",
        "        if (i + 1) % chunk_size == 0:\n",
        "\n",
        "            # 청크를 DataFrame으로 변환\n",
        "            df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "            # 결측치 제거\n",
        "            df_chunk = df_chunk.dropna()\n",
        "\n",
        "            # 필요 없는 컬럼 제거\n",
        "            df_chunk = df_chunk.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "            # YB 그룹과 OB 그룹으로 나누기\n",
        "            yb_group = df_chunk[df_chunk['age_group'].isin(yb_group_range)]\n",
        "            ob_group = df_chunk[df_chunk['age_group'].isin(ob_group_range)]\n",
        "\n",
        "            # YB 그룹 샘플링\n",
        "            if yb_current_sampled < yb_sample_size:\n",
        "                yb_sample_chunk_size = min(yb_sample_size - yb_current_sampled, len(yb_group))\n",
        "                yb_sample_chunk = yb_group.sample(n=yb_sample_chunk_size, random_state=42)\n",
        "                yb_current_sampled += yb_sample_chunk_size\n",
        "            else:\n",
        "                yb_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # OB 그룹 샘플링\n",
        "            if ob_current_sampled < ob_sample_size:\n",
        "                ob_sample_chunk_size = min(ob_sample_size - ob_current_sampled, len(ob_group))\n",
        "                ob_sample_chunk = ob_group.sample(n=ob_sample_chunk_size, random_state=42)\n",
        "                ob_current_sampled += ob_sample_chunk_size\n",
        "            else:\n",
        "                ob_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # YB와 OB 샘플을 합치기\n",
        "            combined_chunk = pd.concat([yb_sample_chunk, ob_sample_chunk])\n",
        "\n",
        "            # CSV 파일로 저장\n",
        "            combined_chunk.to_csv(output_csv_file, mode='a', header=not os.path.exists(output_csv_file), index=False)\n",
        "\n",
        "            # 청크 비우기\n",
        "            chunk = []\n",
        "\n",
        "            # 샘플이 모두 완료되면 중단\n",
        "            if yb_current_sampled >= yb_sample_size and ob_current_sampled >= ob_sample_size:\n",
        "                break\n",
        "\n",
        "    # 마지막 남은 청크 처리\n",
        "    if chunk:\n",
        "        df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "        # 결측치 제거\n",
        "        df_chunk = df_chunk.dropna()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ0f_eX189nD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ijson\n",
        "import os\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/processed_20230501.json'\n",
        "output_csv_file = '/content/final_20230501.csv'\n",
        "\n",
        "# YB와 OB 그룹의 나이 구간 설정\n",
        "yb_group_range = range(0, 4)\n",
        "ob_group_range = range(4, 10)\n",
        "\n",
        "# 샘플 크기 설정\n",
        "total_sample_size = 40000\n",
        "yb_ratio = 0.5\n",
        "ob_ratio = 1 - yb_ratio\n",
        "\n",
        "yb_sample_size = int(total_sample_size * yb_ratio)\n",
        "ob_sample_size = total_sample_size - yb_sample_size\n",
        "\n",
        "# 샘플링을 추적하기 위한 변수\n",
        "yb_current_sampled = 0\n",
        "ob_current_sampled = 0\n",
        "\n",
        "# 한 번에 처리할 청크 크기 (10만 개씩)\n",
        "chunk_size = 100000\n",
        "\n",
        "\n",
        "# JSON 파일을 청크로 나눠서 스트리밍 방식으로 처리\n",
        "with open(input_file_path, 'r') as file:\n",
        "    objects = ijson.items(file, 'item')\n",
        "\n",
        "    chunk = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        chunk.append(obj)\n",
        "\n",
        "        # 청크 크기에 도달할 때마다 처리\n",
        "        if (i + 1) % chunk_size == 0:\n",
        "\n",
        "            # 청크를 DataFrame으로 변환\n",
        "            df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "            # 결측치 제거\n",
        "            df_chunk = df_chunk.dropna()\n",
        "\n",
        "            # 필요 없는 컬럼 제거\n",
        "            df_chunk = df_chunk.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "            # YB 그룹과 OB 그룹으로 나누기\n",
        "            yb_group = df_chunk[df_chunk['age_group'].isin(yb_group_range)]\n",
        "            ob_group = df_chunk[df_chunk['age_group'].isin(ob_group_range)]\n",
        "\n",
        "            # YB 그룹 샘플링\n",
        "            if yb_current_sampled < yb_sample_size:\n",
        "                yb_sample_chunk_size = min(yb_sample_size - yb_current_sampled, len(yb_group))\n",
        "                yb_sample_chunk = yb_group.sample(n=yb_sample_chunk_size, random_state=42)\n",
        "                yb_current_sampled += yb_sample_chunk_size\n",
        "            else:\n",
        "                yb_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # OB 그룹 샘플링\n",
        "            if ob_current_sampled < ob_sample_size:\n",
        "                ob_sample_chunk_size = min(ob_sample_size - ob_current_sampled, len(ob_group))\n",
        "                ob_sample_chunk = ob_group.sample(n=ob_sample_chunk_size, random_state=42)\n",
        "                ob_current_sampled += ob_sample_chunk_size\n",
        "            else:\n",
        "                ob_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # YB와 OB 샘플을 합치기\n",
        "            combined_chunk = pd.concat([yb_sample_chunk, ob_sample_chunk])\n",
        "\n",
        "            # CSV 파일로 저장\n",
        "            combined_chunk.to_csv(output_csv_file, mode='a', header=not os.path.exists(output_csv_file), index=False)\n",
        "\n",
        "            # 청크 비우기\n",
        "            chunk = []\n",
        "\n",
        "            # 샘플이 모두 완료되면 중단\n",
        "            if yb_current_sampled >= yb_sample_size and ob_current_sampled >= ob_sample_size:\n",
        "                break\n",
        "\n",
        "    # 마지막 남은 청크 처리\n",
        "    if chunk:\n",
        "        df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "        # 결측치 제거\n",
        "        df_chunk = df_chunk.dropna()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y61l8cRB9Adz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ijson\n",
        "import os\n",
        "\n",
        "# JSON 파일 경로\n",
        "input_file_path = '/content/processed_20231201.json'\n",
        "output_csv_file = '/content/final_20231201.csv'\n",
        "\n",
        "# YB와 OB 그룹의 나이 구간 설정\n",
        "yb_group_range = range(0, 4)\n",
        "ob_group_range = range(4, 10)\n",
        "\n",
        "# 샘플 크기 설정\n",
        "total_sample_size = 40000\n",
        "yb_ratio = 0.5\n",
        "ob_ratio = 1 - yb_ratio\n",
        "\n",
        "yb_sample_size = int(total_sample_size * yb_ratio)\n",
        "ob_sample_size = total_sample_size - yb_sample_size\n",
        "\n",
        "# 샘플링을 추적하기 위한 변수\n",
        "yb_current_sampled = 0\n",
        "ob_current_sampled = 0\n",
        "\n",
        "# 한 번에 처리할 청크 크기 (10만 개씩)\n",
        "chunk_size = 100000\n",
        "\n",
        "\n",
        "# JSON 파일을 청크로 나눠서 스트리밍 방식으로 처리\n",
        "with open(input_file_path, 'r') as file:\n",
        "    objects = ijson.items(file, 'item')\n",
        "\n",
        "    chunk = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        chunk.append(obj)\n",
        "\n",
        "        # 청크 크기에 도달할 때마다 처리\n",
        "        if (i + 1) % chunk_size == 0:\n",
        "\n",
        "            # 청크를 DataFrame으로 변환\n",
        "            df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "            # 결측치 제거\n",
        "            df_chunk = df_chunk.dropna()\n",
        "\n",
        "            # 필요 없는 컬럼 제거\n",
        "            df_chunk = df_chunk.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "            # YB 그룹과 OB 그룹으로 나누기\n",
        "            yb_group = df_chunk[df_chunk['age_group'].isin(yb_group_range)]\n",
        "            ob_group = df_chunk[df_chunk['age_group'].isin(ob_group_range)]\n",
        "\n",
        "            # YB 그룹 샘플링\n",
        "            if yb_current_sampled < yb_sample_size:\n",
        "                yb_sample_chunk_size = min(yb_sample_size - yb_current_sampled, len(yb_group))\n",
        "                yb_sample_chunk = yb_group.sample(n=yb_sample_chunk_size, random_state=42)\n",
        "                yb_current_sampled += yb_sample_chunk_size\n",
        "            else:\n",
        "                yb_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # OB 그룹 샘플링\n",
        "            if ob_current_sampled < ob_sample_size:\n",
        "                ob_sample_chunk_size = min(ob_sample_size - ob_current_sampled, len(ob_group))\n",
        "                ob_sample_chunk = ob_group.sample(n=ob_sample_chunk_size, random_state=42)\n",
        "                ob_current_sampled += ob_sample_chunk_size\n",
        "            else:\n",
        "                ob_sample_chunk = pd.DataFrame()\n",
        "\n",
        "            # YB와 OB 샘플을 합치기\n",
        "            combined_chunk = pd.concat([yb_sample_chunk, ob_sample_chunk])\n",
        "\n",
        "            # CSV 파일로 저장\n",
        "            combined_chunk.to_csv(output_csv_file, mode='a', header=not os.path.exists(output_csv_file), index=False)\n",
        "\n",
        "            # 청크 비우기\n",
        "            chunk = []\n",
        "\n",
        "            # 샘플이 모두 완료되면 중단\n",
        "            if yb_current_sampled >= yb_sample_size and ob_current_sampled >= ob_sample_size:\n",
        "                break\n",
        "\n",
        "    # 마지막 남은 청크 처리\n",
        "    if chunk:\n",
        "        df_chunk = pd.DataFrame(chunk)\n",
        "\n",
        "        # 결측치 제거\n",
        "        df_chunk = df_chunk.dropna()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMvstujgHRec"
      },
      "source": [
        "7. csv 내용물 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBPcEtHwFox-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dfdf01=pd.read_csv('final_20230101.csv')\n",
        "dfdf01"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wSUOxDJDBM5raTDO72Q7IAHSgUGyab1t",
      "authorship_tag": "ABX9TyMpZqPJe7194Lj3wNyLcP4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}